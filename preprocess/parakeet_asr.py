import os
import sys
from pathlib import Path

import torch
from moviepy import AudioFileClip  # æ–°å¢ï¼šä½¿ç”¨ moviepy è·å–éŸ³é¢‘æ—¶é•¿
import datetime  # æ–°å¢ï¼šç”¨äºæ—¶é—´æ ¼å¼åŒ–

# ROOT_DIR = Path(os.getcwd()).as_posix()
# os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
# os.environ['HF_HOME'] = ROOT_DIR + "/models"
# os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = 'true'

print("æ­£åœ¨åŠ è½½ NVIDIA NeMo ASR æ¨¡å‹...è‹¥ä¸å­˜åœ¨å°†ä¸‹è½½")
# print("æ¨¡å‹åç§°: nvidia/parakeet-tdt-0.6b-v2")
# print("è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")

try:
    # è¿™ä¸€æ­¥ä¼šä¸‹è½½å¹¶åŠ è½½æ¨¡å‹ï¼Œéœ€è¦è¾ƒé•¿æ—¶é—´å’Œç½‘ç»œè¿æ¥
    import nemo.collections.asr as nemo_asr

    root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    LOCAL_MODEL_PATH = os.path.join(root_dir, 'models', "parakeet-tdt-0.6b-v2", 'parakeet-tdt-0.6b-v2.nemo')
    asr_model = nemo_asr.models.ASRModel.restore_from(restore_path=LOCAL_MODEL_PATH)
    # asr_model = nemo_asr.models.ASRModel.from_pretrained(model_name=LOCAL_MODEL_PATH)
    # asr_model = nemo_asr.models.ASRModel.from_pretrained(model_name="nvidia/parakeet-tdt-0.6b-v2")
    asr_model.eval()
    device = "cuda" if torch.cuda.is_available() else "cpu"

    asr_model.to(device)
    asr_model.to(torch.float32)

    print("âœ… NeMo ASR æ¨¡å‹åŠ è½½æˆåŠŸï¼")
except Exception as e:
    print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    # print("è¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£… 'nemo_toolkit[asr]' åŠå…¶ä¾èµ–ï¼Œå¹¶æœ‰å¯ç”¨çš„ç½‘ç»œè¿æ¥ã€‚")
    exit(1)

print("=" * 50)


# æ–°å¢ï¼šä½¿ç”¨ moviepy è·å–éŸ³é¢‘æ—¶é•¿
def get_audio_duration(file_path: str) -> float:
    """ä½¿ç”¨ moviepy è·å–éŸ³é¢‘æ–‡ä»¶çš„æ—¶é•¿ï¼ˆç§’ï¼‰"""
    try:
        audio = AudioFileClip(file_path)
        return audio.duration
    except Exception as e:
        print(f"æ— æ³•è·å–æ–‡ä»¶ '{file_path}' çš„æ—¶é•¿: {e}")
        return 0.0


# æ–°å¢ï¼šå°†ç§’æ•°æ ¼å¼åŒ–ä¸º SRT æ—¶é—´æˆ³æ ¼å¼
def format_srt_time(seconds: float) -> str:
    """å°†ç§’æ•°æ ¼å¼åŒ–ä¸º SRT æ—¶é—´æˆ³æ ¼å¼ HH:MM:SS,ms"""
    delta = datetime.timedelta(seconds=seconds)
    # æ ¼å¼åŒ–ä¸º 0:00:05.123000
    s = str(delta)
    # åˆ†å‰²ç§’å’Œå¾®ç§’
    if '.' in s:
        parts = s.split('.')
        integer_part = parts[0]
        fractional_part = parts[1][:3]  # å–å‰ä¸‰ä½æ¯«ç§’
    else:
        integer_part = s
        fractional_part = "000"

    # å¡«å……å°æ—¶ä½
    if len(integer_part.split(':')) == 2:
        integer_part = "0:" + integer_part

    return f"{integer_part},{fractional_part}"


# æ–°å¢ï¼šå°† NeMo çš„åˆ†æ®µæ—¶é—´æˆ³è½¬æ¢ä¸º SRT æ ¼å¼å­—ç¬¦ä¸²
def segments_to_srt(segments: list) -> str:
    """å°† NeMo çš„åˆ†æ®µæ—¶é—´æˆ³è½¬æ¢ä¸º SRT æ ¼å¼å­—ç¬¦ä¸²"""
    srt_content = []
    for i, segment in enumerate(segments):
        start_time = format_srt_time(segment['start'])
        end_time = format_srt_time(segment['end'])
        text = segment['segment'].strip()

        srt_content.append(f"{i + 1}")
        srt_content.append(f"{start_time} --> {end_time}")
        srt_content.append(text)
        srt_content.append("")  # ç©ºè¡Œ

    return '\n'.join(srt_content)


# æ–°å¢ï¼šç”Ÿæˆ SRT å­—å¹•æ–‡ä»¶
def generate_srt_file(segments: list, output_srt_path: str):
    """ç”Ÿæˆ SRT å­—å¹•æ–‡ä»¶"""
    srt_content = segments_to_srt(segments)
    with open(output_srt_path, 'w', encoding='utf-8') as f:
        f.write(srt_content)
    print(f"âœ… SRT å­—å¹•æ–‡ä»¶å·²ç”Ÿæˆï¼š{output_srt_path}")
    return output_srt_path

import torchaudio
def transcribe_audio_with_nemo(audio_path, output_srt_path):
    """ä½¿ç”¨ NeMo ASR æ¨¡å‹è½¬å½•éŸ³é¢‘æ–‡ä»¶å¹¶ç”Ÿæˆ SRT å­—å¹•"""
    print(f"ğŸ”Š æ­£åœ¨è½¬å½•éŸ³é¢‘: {audio_path}")
    all_segments = []
    all_words = []
    cumulative_time_offset = 0.0
    try:
        # å¯¹å½“å‰åˆ‡ç‰‡è¿›è¡Œè½¬å½•
        print("å¼€å§‹è½¬å½•...")
        print("éŸ³é¢‘è·¯å¾„:", audio_path)
        audio, sr = torchaudio.load(audio_path)
        if audio.shape[0] > 1:
            audio = audio.mean(dim=0, keepdim=True)  # æ··åˆä¸ºå•å£°é“

        # å¯é€‰ï¼šä¿å­˜ä¸´æ—¶æ–‡ä»¶æˆ–ç›´æ¥ä¼ é€’ç»™æ¨¡å‹
        torchaudio.save("temp_mono.wav", audio, sr)

        # ä½¿ç”¨è½¬æ¢åçš„éŸ³é¢‘è·¯å¾„è¿›è¡Œ ASR å¤„ç†
        output = asr_model.transcribe(["temp_mono.wav"],timestamps=True)

        # output = asr_model.transcribe([audio_path], )
        print("âœ… éŸ³é¢‘è½¬å½•å®Œæˆ")
        print(output)
        if output and output[0].timestamp:
            # ä¿®æ­£å¹¶æ”¶é›† segment æ—¶é—´æˆ³
            if 'segment' in output[0].timestamp:
                for seg in output[0].timestamp['segment']:
                    seg['start'] += cumulative_time_offset
                    seg['end'] += cumulative_time_offset
                    all_segments.append(seg)

            # ä¿®æ­£å¹¶æ”¶é›† word æ—¶é—´æˆ³
            if 'word' in output[0].timestamp:
                for word in output[0].timestamp['word']:
                    word['start'] += cumulative_time_offset
                    word['end'] += cumulative_time_offset
                    all_words.append(word)

        # æ›´æ–°ä¸‹ä¸€ä¸ªåˆ‡ç‰‡çš„æ—¶é—´åç§»é‡
        # ä½¿ç”¨å®é™…åˆ‡ç‰‡æ—¶é•¿æ¥æ›´æ–°ï¼Œæ›´ç²¾ç¡®
        chunk_actual_duration = get_audio_duration(audio_path)
        cumulative_time_offset += chunk_actual_duration

        # ç”Ÿæˆ SRT æ–‡ä»¶
        generate_srt_file(all_segments, output_srt_path)
        return output_srt_path
    except Exception as e:
        print(f"âŒ è½¬å½•å¤±è´¥ {audio_path}: {str(e)}")
        return None


if __name__ == '__main__':
    # audio_path = r'D:\PycharmProjects\MutilsSingSong\audios\2086-149220-0033.wav'
    audio_path = r'D:\PycharmProjects\MutilsSingSong\audios\7000917742018694406_original.wav'
    audio, sr = torchaudio.load(audio_path)
    if audio.shape[0] > 1:
        audio = audio.mean(dim=0, keepdim=True)  # æ··åˆä¸ºå•å£°é“

    # å¯é€‰ï¼šä¿å­˜ä¸´æ—¶æ–‡ä»¶æˆ–ç›´æ¥ä¼ é€’ç»™æ¨¡å‹
    torchaudio.save("temp_mono.wav", audio, sr)

    # ä½¿ç”¨è½¬æ¢åçš„éŸ³é¢‘è·¯å¾„è¿›è¡Œ ASR å¤„ç†
    output = asr_model.transcribe(["temp_mono.wav"])
    # output = asr_model.transcribe([audio_path])
    print(output)
