import os
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor

from moviepy import VideoFileClip
import warnings


from core.whisper_asr import WhisperModelSingleton

# å®šä¹‰æ¨¡å‹å­˜æ”¾ä½ç½®
root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
AUDIO_DIR = os.path.join(root_dir, "audios")  # éŸ³é¢‘æ–‡ä»¶å­˜å‚¨ç›®å½•
OUTPUT_DIR = os.path.join(root_dir, "output")  # è¾“å‡ºç›®å½•

from difflib import SequenceMatcher


def are_all_sentences_similar(seg1, seg2, threshold=0.8):
    """
    åˆ¤æ–­ä¸¤ä¸ªæ­Œè¯ç‰‡æ®µçš„æ¯ä¸€å¥æ˜¯å¦éƒ½ç›¸ä¼¼ï¼ˆæ¯å¥ç›¸ä¼¼åº¦ >= thresholdï¼‰
    :param seg1: ç‰‡æ®µ1 (tuple)
    :param seg2: ç‰‡æ®µ2 (tuple)
    :param threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
    :return: True/False
    """
    if len(seg1) != len(seg2):
        return False  # åªæ¯”è¾ƒé•¿åº¦ç›¸åŒçš„ç‰‡æ®µ

    return all(SequenceMatcher(None, s1, s2).ratio() >= threshold for s1, s2 in zip(seg1, seg2))



# æä¾›ä¸€ä¸ªå…¨å±€æ¥å£è°ƒç”¨
def get_whisper_model():
    """
    è·å–å•ä¾‹çš„ Whisper æ¨¡å‹
    """
    return WhisperModelSingleton()


def format_timestamp(seconds):
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    seconds = seconds % 60
    milliseconds = int((seconds - int(seconds)) * 1000)
    return f"{hours:02d}:{minutes:02d}:{int(seconds):02d},{milliseconds:03d}"


def generate_srt(segments, output_srt_path):
    with open(output_srt_path, "w", encoding="utf-8") as f:
        index = 1  # åºå·ä»1å¼€å§‹é€’å¢

        for segment in segments:
            start_time = segment.start
            end_time = segment.end
            text = segment.text.strip()

            # åˆ¤æ–­æ˜¯å¦æœ‰é€—å·
            if ',' in text:
                parts = [p.strip() for p in text.split(',') if p.strip()]
                if len(parts) == 0:
                    continue

                # å¹³å‡åˆ†é…æ—¶é—´
                duration = (end_time - start_time) / len(parts)
                times = []

                for i in range(len(parts)):
                    part_start = start_time + i * duration
                    part_end = start_time + (i + 1) * duration
                    times.append((part_start, part_end))

                # å†™å…¥å¤šä¸ªå­—å¹•æ¡ç›®
                for part_text, (part_start, part_end) in zip(parts, times):
                    start = format_timestamp(part_start)
                    end = format_timestamp(part_end)

                    f.write(f"{index}\n")
                    f.write(f"{start} --> {end}\n")
                    f.write(f"{part_text}\n\n")
                    index += 1
            else:
                # æ— é€—å·ï¼Œä¿æŒåŸæ ·è¾“å‡º
                start = format_timestamp(segment.start)
                end = format_timestamp(segment.end)

                f.write(f"{index}\n")
                f.write(f"{start} --> {end}\n")
                f.write(f"{text}\n\n")
                index += 1

    print(f"âœ… SRT å­—å¹•æ–‡ä»¶å·²ç”Ÿæˆï¼š{output_srt_path}")


def extract_audio_from_videos(video_dir, output_dir=AUDIO_DIR):
    """ä»è§†é¢‘ç›®å½•æå–éŸ³é¢‘"""
    os.makedirs(output_dir, exist_ok=True)
    audio_files = []

    for video_file in os.listdir(video_dir):
        if video_file.endswith(('.mp4', '.avi', '.mov')):
            video_path = os.path.join(video_dir, video_file)
            audio_path = os.path.join(output_dir, os.path.splitext(video_file)[0] + ".wav")

            if not os.path.exists(audio_path):
                try:
                    video = VideoFileClip(video_path)
                    video.audio.write_audiofile(audio_path, codec='pcm_s16le')
                    audio_files.append(audio_path)
                except Exception as e:
                    print(f"âŒ æå–éŸ³é¢‘å¤±è´¥ {video_file}: {str(e)}")
            else:
                audio_files.append(audio_path)
    return audio_files


def batch_whisper_transcribe_audio(audio_files):
    """æ‰¹é‡è½¬å½•éŸ³é¢‘æ–‡ä»¶"""
    whisper = get_whisper_model()
    srt_files = []

    with ThreadPoolExecutor() as executor:
        futures = []
        for audio_path in audio_files:
            base_name = os.path.basename(audio_path).replace(".wav", "")
            output_srt_path = os.path.join(OUTPUT_DIR, f"{base_name}.srt")

            if not os.path.exists(output_srt_path):
                future = executor.submit(process_single_audio, whisper, audio_path, output_srt_path)
                futures.append((future, output_srt_path))  # âœ… æŠŠ future å’Œ srt_path ä¸€èµ·ä¿å­˜
            else:
                srt_files.append(output_srt_path)
        for future, srt_path in futures:
            try:
                future.result()
                srt_files.append(srt_path)
            except Exception as e:
                print(f"âŒ è½¬å½•å¤±è´¥: {str(e)}")

    return srt_files


def process_single_audio(whisper, audio_path, output_srt_path):
    """å¤„ç†å•ä¸ªéŸ³é¢‘æ–‡ä»¶"""
    print(f"ğŸ”Š å¤„ç†éŸ³é¢‘: {audio_path}")
    segments, _ = whisper.transcribe(audio_path, beam_size=7,language="en", condition_on_previous_text=False, word_timestamps=True)
    generate_srt(segments, output_srt_path)
    return output_srt_path


def load_srt_content(srt_file):
    with open(srt_file, 'r', encoding='utf-8') as f:
        content = f.read().strip().split('\n\n')
    lyrics = []
    for block in content:
        lines = block.split('\n')
        if len(lines) >= 3:
            lyrics.append(lines[2].strip())  # æå–æ­Œè¯æ–‡æœ¬
    return lyrics


def parse_time(time_str):
    """è§£ææ—¶é—´å­—ç¬¦ä¸²ä¸ºç§’æ•°"""
    h, m, s = time_str.replace(',', '.').split(':')
    return int(h) * 3600 + int(m) * 60 + float(f"{s[:2]}.{s[3:]}")


def extract_segments_multi_length(lyrics_list, min_length=3, max_length=7):
    """
    æå–æ‰€æœ‰é•¿åº¦åœ¨ [min_length, max_length] èŒƒå›´å†…çš„è¿ç»­æ­Œè¯ç‰‡æ®µ
    """
    segments = []
    for length in range(min_length, max_length + 1):
        for i in range(len(lyrics_list) - length + 1):
            segment = tuple(lyrics_list[i:i + length])
            segments.append((segment, length))  # å¸¦ä¸Šé•¿åº¦ä¿¡æ¯ç”¨äºåç»­å¤„ç†
    return segments


def merge_overlapping_segments(candidate_segments):
    """
    åˆå¹¶é‡å¤/åŒ…å«å…³ç³»çš„ç‰‡æ®µï¼Œä¿ç•™æœ€é•¿ä¸”ä¸è¢«å…¶ä»–ç‰‡æ®µåŒ…å«çš„ç‰‡æ®µ
    :param candidate_segments: [(segment, files, length), ...]
    :return: merged_segments
    """
    # å…ˆæŒ‰é•¿åº¦æ’åºï¼Œé•¿çš„ä¼˜å…ˆä¿ç•™
    sorted_segments = sorted(candidate_segments, key=lambda x: -x[2])

    result = []
    used_indices = set()

    for i, (seg, files, length) in enumerate(sorted_segments):
        is_contained = False
        for j, (seg_j, _, _) in enumerate(sorted_segments):
            if i == j or j in used_indices:
                continue
            # å¦‚æœå½“å‰ç‰‡æ®µè¢«æ›´é•¿çš„ç‰‡æ®µåŒ…å«ï¼Œåˆ™è·³è¿‡
            if is_segment_contained(seg, seg_j):
                is_contained = True
                break
        if not is_contained:
            result.append((seg, files))
            used_indices.add(i)

    return result


def is_segment_contained(shorter, longer):
    """åˆ¤æ–­ shorter æ˜¯å¦å®Œå…¨åŒ…å«åœ¨ longer ä¸­"""
    shorter_str = " ".join(shorter)
    longer_str = " ".join(longer)
    return shorter_str in longer_str and len(shorter) < len(longer)


from itertools import combinations


def find_common_segments(srt_files, min_files=4, min_segment_length=4, max_segment_length=10, similarity_threshold=0.8):
    file_lyrics = {}
    all_segments = []

    # æå–æ¯ä¸ªæ–‡ä»¶ä¸­çš„æ‰€æœ‰ç‰‡æ®µ
    for srt_file in srt_files:
        lyrics = load_srt_content(srt_file)
        segments_with_length = extract_segments_multi_length(lyrics, min_segment_length, max_segment_length)
        segments_only = [seg for seg, length in segments_with_length]
        file_lyrics[srt_file] = lyrics
        all_segments.extend(segments_only)

    # æ„å»ºä¸€ä¸ªâ€œä¸»ç‰‡æ®µæ± â€ï¼Œç”¨äºåˆå¹¶ç›¸ä¼¼ç‰‡æ®µ
    unique_segments = []
    # åœ¨æ„å»ºä¸»ç‰‡æ®µæ± æ—¶ä½¿ç”¨æ–°å‡½æ•°
    for segment in all_segments:
        matched = False
        for us in unique_segments:
            if are_all_sentences_similar(segment, us, similarity_threshold):
                matched = True
                break
        if not matched:
            unique_segments.append(segment)

    # ç»Ÿè®¡æ¯ä¸ªä¸»ç‰‡æ®µå‡ºç°åœ¨å“ªäº›æ–‡ä»¶ä¸­
    segment_to_files = defaultdict(set)
    for srt_file in srt_files:
        lyrics = file_lyrics[srt_file]
        segments_only = extract_segments_multi_length(lyrics, min_segment_length, max_segment_length)
        segments_only = [seg for seg, length in segments_only]
        # ç»Ÿè®¡æ¯ä¸ªä¸»ç‰‡æ®µå‡ºç°åœ¨å“ªäº›æ–‡ä»¶ä¸­
        for seg in segments_only:
            for main_seg in unique_segments:
                if are_all_sentences_similar(seg, main_seg, similarity_threshold):
                    segment_to_files[main_seg].add(srt_file)
                    break

    # ç­›é€‰å‡ºç°æ¬¡æ•° >= min_files çš„ç‰‡æ®µ
    candidate_segments = [
        (seg, list(files)) for seg, files in segment_to_files.items()
        if len(files) >= min_files and len(seg) >= min_segment_length
    ]

    # åˆå¹¶é‡å æˆ–åŒ…å«å…³ç³»çš„ç‰‡æ®µï¼Œä¿ç•™æœ€é•¿çš„
    merged_segments = merge_overlapping_segments([(seg, files, len(seg)) for seg, files in candidate_segments])

    return merged_segments, file_lyrics


def locate_segments_in_srt(srt_file, target_segment, file_lyrics, similarity_threshold=0.7):
    lyrics = file_lyrics[srt_file]
    segment_length = len(target_segment)

    start_indices = []
    for i in range(len(lyrics) - segment_length + 1):
        current_segment = tuple(lyrics[i:i + segment_length])
        if are_all_sentences_similar(current_segment, target_segment, similarity_threshold):
            start_indices.append(i)

    # è§£ææ—¶é—´æˆ³
    time_ranges = []
    with open(srt_file, 'r', encoding='utf-8') as f:
        content = f.read().strip().split('\n\n')

    for start_idx in start_indices:
        start_time = parse_time(content[start_idx].split('\n')[1].split(' --> ')[0])
        end_time = parse_time(content[start_idx + segment_length - 1].split('\n')[1].split(' --> ')[1])
        time_ranges.append((start_time, end_time))

    return time_ranges


def crop_videos_based_on_common_segments(common_segments, file_lyrics, video_dir, output_dir, similarity_threshold=0.8):
    os.makedirs(output_dir, exist_ok=True)

    # æ‰¾åˆ°æ®µæ•°æœ€å¤šçš„æ­Œè¯ç‰‡æ®µçš„æœ€å¤§æ®µæ•°
    # max_segment_length = sorted([len(segment) for segment, srt_files in common_segments])
    # #
    # # # ç­›é€‰å‡ºæ‰€æœ‰è¾¾åˆ°æœ€å¤§æ®µæ•°çš„æ­Œè¯ç‰‡æ®µ
    # max_segments = [(segment, srt_files) for segment, srt_files in common_segments if
    #                 len(segment) == max_segment_length]

    for idx, (segment, srt_files) in enumerate(common_segments):
        # print(f"ğŸ“¦ æ­£åœ¨å¤„ç†ç¬¬ {idx + 1} ç»„æ­Œè¯ç‰‡æ®µï¼ˆæ®µæ•°æœ€å¤šï¼‰ï¼š{segment}")
        segment_dir = os.path.join(output_dir, f"segment_{idx + 1}")
        os.makedirs(segment_dir, exist_ok=True)
        for srt_file in srt_files:
            video_file = os.path.splitext(os.path.basename(srt_file))[0] + ".mp4"
            video_path = os.path.join(video_dir, video_file)

            if not os.path.exists(video_path):
                print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼š{video_path}")
                continue

            try:
                video = VideoFileClip(video_path)
                time_ranges = locate_segments_in_srt(srt_file, segment, file_lyrics,
                                                     similarity_threshold=similarity_threshold)

                for i, (start, end) in enumerate(time_ranges):
                    subclip = video.subclipped(start, end)
                    output_path = os.path.join(segment_dir, f"{os.path.splitext(video_file)[0]}_seg{i + 1}.mp4")
                    subclip.write_videofile(
                        output_path,
                        codec='libx264',
                        audio_codec='aac'
                    )
                    print(f"âœ… å·²ç”Ÿæˆè£å‰ªè§†é¢‘ï¼š{output_path}")
            except Exception as e:
                print(f"âŒ è£å‰ªå¤±è´¥ï¼š{video_file}ï¼Œé”™è¯¯ï¼š{str(e)}")


def whisper_main(video_dir):
    # 1. æå–éŸ³é¢‘
    audio_files = extract_audio_from_videos(video_dir)
    print(f"âœ… å·²æå–éŸ³é¢‘æ–‡ä»¶: {audio_files}")

    # 2. æ‰¹é‡è½¬å½•
    srt_files = batch_whisper_transcribe_audio(audio_files)

    print(f"âœ… å·²ç”ŸæˆSRTæ–‡ä»¶: {srt_files}")

    # 3. æŸ¥æ‰¾å…±åŒæ­Œè¯ç‰‡æ®µï¼ˆè‡³å°‘4ä¸ªæ–‡ä»¶ä¸­å‡ºç°ï¼Œ7æ®µè¿ç»­ï¼‰
    common_segments, file_lyrics = find_common_segments(srt_files, min_files=4, min_segment_length=4,
                                                        max_segment_length=40, similarity_threshold=0.3)
    print(f"âœ… å…±åŒæ­Œè¯ç‰‡æ®µï¼š{common_segments}")
    if not common_segments:
        print("âš ï¸ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ­Œè¯ç‰‡æ®µ")
        return

    # 4. è£å‰ªè§†é¢‘
    output_dir = os.path.join(root_dir, "output", "cropped")
    crop_videos_based_on_common_segments(common_segments, file_lyrics, video_dir, output_dir, similarity_threshold=0.3)

def parakeet_main(video_dir):
    from core.parakeet_asr import transcribe_audio_with_nemo
    audio_files = extract_audio_from_videos(video_dir, output_dir=AUDIO_DIR)

    if not audio_files:
        print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„éŸ³é¢‘æ–‡ä»¶")
        return []

    # ç¬¬äºŒæ­¥ï¼šå¯¹æ¯ä¸ªéŸ³é¢‘æ–‡ä»¶è¿›è¡Œè½¬å½•
    srt_files = []
    for audio_path in audio_files:

        base_name = os.path.basename(audio_path).replace(".wav", "")
        output_srt_path = os.path.join(OUTPUT_DIR, f"{base_name}.srt")

        if not os.path.exists(output_srt_path):
            result = transcribe_audio_with_nemo(audio_path, output_srt_path)
            if result:
                srt_files.append(result)
        else:
            srt_files.append(output_srt_path)

    print(f"âœ… å·²ç”ŸæˆSRTæ–‡ä»¶: {srt_files}")

    # 3. æŸ¥æ‰¾å…±åŒæ­Œè¯ç‰‡æ®µï¼ˆè‡³å°‘4ä¸ªæ–‡ä»¶ä¸­å‡ºç°ï¼Œ7æ®µè¿ç»­ï¼‰
    common_segments, file_lyrics = find_common_segments(srt_files, min_files=4, min_segment_length=4,
                                                        max_segment_length=40, similarity_threshold=0.7)
    print(f"âœ… å…±åŒæ­Œè¯ç‰‡æ®µï¼š{common_segments}")
    if not common_segments:
        print("âš ï¸ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ­Œè¯ç‰‡æ®µ")
        return

    # 4. è£å‰ªè§†é¢‘
    output_dir = os.path.join(root_dir, "output", "cropped")
    crop_videos_based_on_common_segments(common_segments, file_lyrics, video_dir, output_dir, similarity_threshold=0.7)


if __name__ == '__main__':
    # main(os.path.join(root_dir,  "pre","male"))
    # main(os.path.join(root_dir,  "pre/1"))
    # whisper_main(os.path.join(root_dir,  "pre/13"))
    whisper_main(os.path.join(root_dir,  "pre/14"))
    # parakeet_main(os.path.join(root_dir,  "pre/8"))
    # main(os.path.join(root_dir,  "pre/4"))
    # main(os.path.join(root_dir,  "pre"))
    # main(os.path.join(root_dir,  "pre","han"))