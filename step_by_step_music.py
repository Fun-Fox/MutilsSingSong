import datetime
import random

from moviepy import VideoFileClip
import os
import shutil
import librosa
import tempfile
import cv2
import pyJianYingDraft.pyJianYingDraft as draft
from pyJianYingDraft.pyJianYingDraft import Clip_settings, Export_resolution, Export_framerate, trange, Font_type, \
    Text_style, Text_loop_anim

root_dir = os.path.dirname(os.path.abspath(__file__))


def export_step_by_step_music_video(video_folder):
    # === ç¬¬ä¸€æ­¥ï¼šä»ç¬¬ä¸€ä¸ªè§†é¢‘æå–å¡ç‚¹æ—¶é—´ç‚¹ ===

    # è·å– video_folder è·¯å¾„ä¸‹çš„æ‰€æœ‰ .mp4 è§†é¢‘æ–‡ä»¶
    video_files = [f for f in os.listdir(video_folder) if f.endswith(".mp4")]
    random.shuffle(video_files)
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨è‡³å°‘ä¸€ä¸ªè§†é¢‘æ–‡ä»¶
    if video_files:
        # å–ç¬¬ä¸€ä¸ªè§†é¢‘æ–‡ä»¶ä½œä¸º first_video_path
        first_video_path = os.path.join(video_folder, video_files[0])
        print(f"âœ… ç¬¬ä¸€ä¸ªè§†é¢‘è·¯å¾„ä¸º: {first_video_path}")
    else:
        raise FileNotFoundError("æœªæ‰¾åˆ°ä»»ä½• .mp4 è§†é¢‘æ–‡ä»¶")

    # åŠ è½½ç¬¬ä¸€ä¸ªè§†é¢‘
    print("ğŸ“˜ æ­£åœ¨åŠ è½½ç¬¬ä¸€ä¸ªè§†é¢‘...")
    video = VideoFileClip(first_video_path)

    # åˆ›å»ºä¸´æ—¶ç›®å½•ä¿å­˜éŸ³é¢‘
    temp_dir = tempfile.mkdtemp()
    audio_path = os.path.join(temp_dir, "audio.wav")
    print(f"ğŸ“ å·²åˆ›å»ºä¸´æ—¶éŸ³é¢‘æ–‡ä»¶å¤¹: {temp_dir}")

    # æå–éŸ³é¢‘å¹¶ä¿å­˜ä¸º WAV æ–‡ä»¶
    print("ğŸµ æ­£åœ¨æå–éŸ³é¢‘...")
    video.audio.write_audiofile(audio_path, codec='pcm_s16le')

    # æå–éŸ³é¢‘å¹¶æ£€æµ‹èŠ‚æ‹
    print("ğŸ¼ æ­£åœ¨åˆ†æéŸ³é¢‘èŠ‚å¥...")
    y, sr = librosa.load(audio_path, sr=None)
    tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)
    beat_times = librosa.frames_to_time(beat_frames, sr=sr)

    # è®¾ç½®æœ€å°é—´éš”ä¸º 5 ç§’ï¼Œå¹¶è¿‡æ»¤å¯†é›†å¡ç‚¹
    segment_duration = 4
    # if video.duration / 4.5 > 10:
    #     segment_duration = 4.5
    # if video.duration / 7 > 7:
    #     segment_duration = 7

    MIN_INTERVAL = video.duration / segment_duration - 0.5
    MAX_INTERVAL = video.duration / segment_duration
    filtered_beat_times = []
    last_time = -MIN_INTERVAL

    for time in sorted(beat_times):
        interval = time - last_time
        if interval >= MIN_INTERVAL:
            # å¦‚æœé—´éš”è¶…è¿‡æœ€å¤§é—´éš”ï¼Œå¯ä»¥æ’å…¥ä¸€ä¸ªä¸­é—´ç‚¹
            while interval > MAX_INTERVAL:
                last_time += MAX_INTERVAL
                filtered_beat_times.append(last_time)
                interval = time - last_time
            filtered_beat_times.append(time)
            last_time = time

    rounded_beat_times = [round(t, 2) for t in filtered_beat_times]
    print(f"âœ… æ£€æµ‹åˆ°èŠ‚å¥å¡ç‚¹æ—¶é—´ï¼ˆç§’ï¼‰ï¼š{rounded_beat_times}")

    # æ„é€ ç‰‡æ®µåŒºé—´
    segments = [(rounded_beat_times[i], rounded_beat_times[i + 1]) for i in range(len(rounded_beat_times) - 1)]

    if filtered_beat_times:
        last_time = rounded_beat_times[-1]
        if last_time < video.duration:  # ç¡®ä¿è¿˜æœ‰å‰©ä½™å†…å®¹
            segments.append((last_time, video.duration))
            print(f"ğŸ“ å·²æ·»åŠ å°¾æ®µï¼š{last_time:.2f}s åˆ° {video.duration:.2f}s")
    print(f"âœ‚ï¸ å·²æ„é€ è§†é¢‘{len(segments)}ä¸ªç‰‡æ®µåŒºé—´ï¼š{segments}")

    # åˆ é™¤ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
    shutil.rmtree(temp_dir)
    print("ğŸ—‘ï¸ å·²åˆ é™¤ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶")

    # === ç¬¬äºŒæ­¥ï¼šéå†æ‰€æœ‰è§†é¢‘ï¼ŒæŒ‰ä¸Šè¿°ç‰‡æ®µæˆªå›¾ ===
    # 2.1 å‰ªæ˜ è‰ç¨¿ç”Ÿæˆ

    base_folder = os.path.join(
        # LOCALAPPDATA æ˜¯ Windows ç³»ç»Ÿä¸­çš„ä¸€ä¸ªç¯å¢ƒå˜é‡ï¼Œè¡¨ç¤ºå½“å‰ç”¨æˆ·çš„æœ¬åœ°åº”ç”¨ç¨‹åºæ•°æ®å­˜å‚¨è·¯å¾„
        # C:\Users\<ç”¨æˆ·å>\AppData\Local
        os.getenv("LOCALAPPDATA"),
        "JianyingPro\\User Data\\Projects\\com.lveditor.draft"
    )
    draft_folder_name = 'å››å®«æ ¼æ¥åŠ›ç¿»å”±'
    # ä¿å­˜è·¯å¾„
    DUMP_PATH = os.path.join(base_folder, draft_folder_name, "draft_content.json")
    os.makedirs(os.path.dirname(DUMP_PATH), exist_ok=True)

    # åˆ›å»ºå‰ªæ˜ è‰ç¨¿
    script = draft.Script_file(1080, 1920)  # 1920x1080åˆ†è¾¨ç‡

    script.add_track(draft.Track_type.text, track_name=f'text-title', relative_index=100)
    text = "Can You Keep Up with the Lyrics?"
    # "Which cover is best?"
    text_segment = draft.Text_segment(text, trange("0s", "10s"),
                                      font=Font_type.æ–°é’å¹´ä½“,
                                      style=Text_style(size=14.0, color=(1.0, 1.0, 1.0), underline=False, align=1),
                                      clip_settings=Clip_settings(transform_y=0))
    effect_ids = [
        "7351319129124506930",
        "7506817303296675123",
        "7507075178447359282",
        "6896144021568179469",
        "6896137924853763336",
        "7244707954585292064",
        "7404300897628540211"
    ]

    # éšæœºé€‰ä¸€ä¸ªç‰¹æ•ˆ
    selected_effect = random.choice(effect_ids)

    text_segment.add_effect(selected_effect)
    script.add_segment(text_segment, "text-title")

    # 2.2 ä¸€è¾¹ä¿å­˜ç´ æï¼Œä¸€è¾¹ç”Ÿæˆå‰ªæ˜ è‰ç¨¿

    output_folder = os.path.join(video_folder, "captured_frames")
    os.makedirs(output_folder, exist_ok=True)
    print(f"ğŸ“¸ å›¾ç‰‡è¾“å‡ºè·¯å¾„å·²è®¾ç½®ä¸º: {output_folder}")

    video_files = [f for f in os.listdir(video_folder) if f.endswith(".mp4")]
    print(f"ğŸï¸ æ£€æµ‹åˆ°ä»¥ä¸‹è§†é¢‘æ–‡ä»¶ï¼š{video_files}")

    def add_video_material(start_time, output_video_path, transform_x, transform_y):
        video_material = draft.Video_material(output_video_path)
        print(f"ğŸ¬ æ·»åŠ è§†é¢‘ï¼š{output_video_path}ï¼Œ\n å¼€å§‹æ—¶é—´{start_time}ï¼Œæ—¶é•¿{video_material.duration}")
        video_segment = draft.Video_segment(video_material,
                                            draft.Timerange(start_time, video_material.duration),
                                            source_timerange=draft.Timerange(0, video_material.duration),
                                            clip_settings=Clip_settings(scale_x=0.5, scale_y=0.5,
                                                                        transform_x=transform_x,
                                                                        transform_y=transform_y))  # ä¸ç´ æç­‰é•¿
        print(f"ğŸ¬ æ·»åŠ åˆ°è§†é¢‘è½¨é“{idx}-{video_file}-video")
        # æ·»åŠ åˆ°è½¨é“
        script.add_segment(video_segment, f'{idx}-{video_file}-video', )
        start_time += video_material.duration
        return start_time, script

    # å¢åŠ å°é¢è½¨é“
    script.add_track(draft.Track_type.video, track_name=f'å°é¢', relative_index=0)

    def add_end_frame_image(script, start_time, output_path_end, transform_x, transform_y):
        # if start_time + 1000000 < (video.duration * 1000000):
        script.add_track(draft.Track_type.video, track_name=f'{idx}-{output_path_end}-image',
                         relative_index=(idx + 5) * 2 - i + 1)
        video_material = draft.Video_material(output_path_end)
        print(f"å›¾ç‰‡æ·»åŠ è§†é¢‘ï¼š{output_video_path}ï¼Œ\n å¼€å§‹æ—¶é—´{start_time}ï¼Œæ—¶é•¿{video_material.duration}")
        video_segment = draft.Video_segment(video_material,
                                            # 7s= 7000000
                                            target_timerange=draft.Timerange(start_time, MAX_INTERVAL * 1000000 * 3),
                                            source_timerange=draft.Timerange(0, video_material.duration),
                                            clip_settings=Clip_settings(scale_x=0.5, scale_y=0.5,
                                                                        transform_x=transform_x,
                                                                        transform_y=transform_y))  # ä¸ç´ æç­‰é•¿
        print(f"å›¾ç‰‡æ·»åŠ åˆ°è§†é¢‘è½¨é“{idx}-{video_file}")
        # æ·»åŠ åˆ°è½¨é“
        script.add_segment(video_segment, f'{idx}-{output_path_end}-image', )

    #  å¢åŠ emoji
    emoji = [
        "ğŸ˜Š", "ğŸ˜„", "ğŸ˜ƒ", "ğŸ˜", "ğŸ˜†", "ğŸ˜…", "ğŸ˜‚", "ğŸ¤£", "â˜ºï¸", "ğŸ˜‡",
        "ğŸ¥°", "ğŸ˜", "ğŸ¤©", "ğŸ¥³", "ğŸ¤—", "ğŸ˜‹", "ğŸ˜Œ", "ğŸ˜", "ğŸ˜", "ğŸ¤“",
        "ğŸ‘¶", "ğŸ˜‚", "ğŸ¤£", "ğŸ˜…", "ğŸ˜†", "ğŸ˜ˆ", "ğŸ˜º", "ğŸ˜¸", "ğŸ˜»", "ğŸ˜½"
    ]
    for idx, video_file in enumerate(video_files):
        video_path = os.path.join(video_folder, video_file)
        print(f"\nğŸ¬ æ­£åœ¨å¤„ç†è§†é¢‘ï¼š{video_file}")

        clip = VideoFileClip(video_path)
        print(f"â±ï¸ è§†é¢‘æ€»æ—¶é•¿ï¼š{clip.duration:.2f} ç§’")

        # æ·»åŠ è§†é¢‘è½¨é“
        script.add_track(draft.Track_type.video, track_name=f'{idx}-{video_file}-video', relative_index=idx * 2 + 100)
        script.add_track(draft.Track_type.text, track_name=f'text-index-{idx}', relative_index=idx * 2 + 200)

        start_time = 0

        random_emoji = random.choice(emoji)

        if idx == 0:
            seg = draft.Text_segment(f"{random_emoji}", trange("0s", f"{int(clip.duration)}s"),
                                     font=Font_type.æ–°é’å¹´ä½“,
                                     style=Text_style(size=12, color=(1.0, 1.0, 1.0), underline=False, align=1,
                                                      bold=True),
                                     clip_settings=Clip_settings(transform_x=-0.2,
                                                                 transform_y=0.2))

        elif idx == 1:

            seg = draft.Text_segment(f"{random_emoji}", trange("0s", f"{int(clip.duration)}s"),
                                     font=Font_type.æ–°é’å¹´ä½“,
                                     style=Text_style(size=12, color=(1.0, 1.0, 1.0), underline=False, align=1,
                                                      bold=True),
                                     clip_settings=Clip_settings(transform_x=0.2, transform_y=0.2))

        elif idx == 2:

            seg = draft.Text_segment(f"{random_emoji}", trange("0s", f"{int(clip.duration)}s"),
                                     font=Font_type.æ–°é’å¹´ä½“,
                                     style=Text_style(size=12, color=(1.0, 1.0, 1.0), underline=False, align=1,
                                                      bold=True),
                                     clip_settings=Clip_settings(transform_x=-0.2,
                                                                 transform_y=-0.2))

        else:

            seg = draft.Text_segment(f"{random_emoji}", trange("0s", f"{int(clip.duration)}s"),
                                     font=Font_type.æ–°é’å¹´ä½“,
                                     style=Text_style(size=15, color=(1.0, 1.0, 1.0), underline=False, align=1,
                                                      bold=True),
                                     clip_settings=Clip_settings(transform_x=0.2,
                                                                 transform_y=-0.2))
        seg.add_animation(Text_loop_anim.å½©è‰²ç«ç„°)
        script.add_segment(seg, f"text-index-{idx}")

        # è£å‰ªçš„èŠ‚ç‚¹ç‰‡æ®µ
        for i, (start, end) in enumerate(segments):

            print(f"\nğŸ“Œ å¤„ç†ç¬¬ {i} ä¸ªç‰‡æ®µï¼šå¼€å§‹æ—¶é—´={start:.2f}sï¼Œç»“æŸæ—¶é—´={end:.2f}s")

            # æå–ç¬¬ä¸€å¸§ï¼ˆstartï¼‰
            try:
                frame_start = clip.get_frame(start)
            except Exception as e:
                print(f"[âŒ é”™è¯¯] è·å–èµ·å§‹å¸§å¤±è´¥: {e}")
                continue

            # æå–æœ€åä¸€å¸§ï¼ˆendï¼‰
            try:
                frame_end = clip.get_frame(end)
            except Exception as e:
                print(f"[âŒ é”™è¯¯] è·å–ç»“æŸå¸§å¤±è´¥: {e}")
                continue

            # è½¬æ¢ä¸º OpenCV å¯ç”¨çš„ BGR æ ¼å¼
            frame_start_bgr = cv2.cvtColor(frame_start, cv2.COLOR_RGB2BGR)
            frame_end_bgr = cv2.cvtColor(frame_end, cv2.COLOR_RGB2BGR)

            # æ„é€ è¾“å‡ºè·¯å¾„
            base_name = os.path.splitext(video_file)[0]

            output_path_start = os.path.join(
                output_folder,
                f"{base_name}_seg_{i:03d}_start_{start:.2f}.jpg"
            )
            output_path_end = os.path.join(
                output_folder,
                f"{base_name}_seg_{i:03d}_end_{end:.2f}.jpg"
            )

            # ä¿å­˜ç¬¬ä¸€å¸§
            success = cv2.imwrite(output_path_start, frame_start_bgr)
            if not success:
                print(f"[âŒ é”™è¯¯] å›¾ç‰‡ä¿å­˜å¤±è´¥ï¼š{output_path_start}")
            # else:
            #     print(f"âœ… å·²ä¿å­˜èµ·å§‹å¸§å›¾ç‰‡è‡³ï¼š{output_path_start}")

            # ä¿å­˜æœ€åä¸€å¸§
            success = cv2.imwrite(output_path_end, frame_end_bgr)
            if not success:
                print(f"[âŒ é”™è¯¯] å›¾ç‰‡ä¿å­˜å¤±è´¥ï¼š{output_path_end}")
            # else:
            #     print(f"âœ… å·²ä¿å­˜ç»“æŸå¸§å›¾ç‰‡è‡³ï¼š{output_path_end}")

            # åˆ›å»ºç‰‡æ®µè§†é¢‘è¾“å‡ºç›®å½•
            segment_video_folder = os.path.join(video_folder, "segment_videos", base_name)
            os.makedirs(segment_video_folder, exist_ok=True)

            # æˆªå–ç‰‡æ®µå¹¶ä¿å­˜
            # ç¤ºä¾‹ä¿®å¤ä»£ç 
            end = min(end, clip.duration, video.duration)  # è‡ªåŠ¨é™åˆ¶ end ä¸è¶…è¿‡è§†é¢‘é•¿åº¦
            if start >= end:
                continue
            sub_clip = clip.subclipped(start, end)

            output_video_path = os.path.join(
                segment_video_folder,
                f"{base_name}_seg_{i:03d}_{start:.2f}_{end:.2f}.mp4"
            )

            # å†™å…¥è§†é¢‘æ–‡ä»¶ï¼ˆä½¿ç”¨ libx264 ç¼–ç ï¼‰
            sub_clip.write_videofile(output_video_path, codec="libx264", audio_codec="aac", logger=None)
            # sub_clip.close()
            print(f"ğŸ’¾ å·²ä¿å­˜è§†é¢‘ç‰‡æ®µè‡³ï¼š{output_video_path}")

            if idx == 0 and i % 4 == 0:
                # ç¬¬ä¸€ä¸ªå®«æ ¼è§†é¢‘æ·»åŠ è§†é¢‘è½¨é“
                start_time, script = add_video_material(start_time, output_video_path, transform_x=-0.5,
                                                        transform_y=0.5)
                # æ·»åŠ é™æ­¢å›¾ç‰‡
                add_end_frame_image(script, start_time, output_path_end, transform_x=-0.5, transform_y=0.5)



            elif idx == 1 and i % 4 == 1:
                # ç¬¬äºŒä¸ªå®«æ ¼è§†é¢‘æ·»åŠ è§†é¢‘è½¨é“

                if i == 1:
                    # æ·»åŠ é¦–å¸§å›¾ç‰‡
                    # ç”Ÿæˆæ¯ä¸ªè½¨é“çš„è‰ç¨¿è„šæœ¬
                    script.add_track(draft.Track_type.video, track_name=f'{idx}-{output_path_start}-image',
                                     relative_index=idx * 2 - i)
                    video_material = draft.Video_material(output_path_start)
                    video_segment = draft.Video_segment(video_material,
                                                        target_timerange=draft.Timerange(0, start_time),
                                                        source_timerange=draft.Timerange(0, video_material.duration),
                                                        clip_settings=Clip_settings(scale_x=0.5, scale_y=0.5,
                                                                                    transform_x=0.5,
                                                                                    transform_y=0.5))  # ä¸ç´ æç­‰é•¿
                    # æ·»åŠ åˆ°è½¨é“
                    script.add_segment(video_segment, f'{idx}-{output_path_start}-image', )

                # æ·»åŠ è§†é¢‘
                start_time, script = add_video_material(start_time, output_video_path, transform_x=0.5, transform_y=0.5)

                # æ·»åŠ é™æ­¢å›¾ç‰‡
                add_end_frame_image(script, start_time, output_path_end, transform_x=0.5, transform_y=0.5)


            elif idx == 2 and i % 4 == 2:
                if i == 2:
                    # æ·»åŠ é¦–å¸§å›¾ç‰‡
                    # ç”Ÿæˆæ¯ä¸ªè½¨é“çš„è‰ç¨¿è„šæœ¬
                    script.add_track(draft.Track_type.video, track_name=f'{idx}-{output_path_start}-image',
                                     relative_index=idx * 2 - i)
                    video_material = draft.Video_material(output_path_start)
                    video_segment = draft.Video_segment(video_material,
                                                        target_timerange=draft.Timerange(0, start_time),
                                                        source_timerange=draft.Timerange(0, video_material.duration),
                                                        clip_settings=Clip_settings(scale_x=0.5, scale_y=0.5,
                                                                                    transform_x=-0.5,
                                                                                    transform_y=-0.5))  # ä¸ç´ æç­‰é•¿
                    # æ·»åŠ åˆ°è½¨é“
                    script.add_segment(video_segment, f'{idx}-{output_path_start}-image', )
                # ç¬¬ä¸‰ä¸ªå®«æ ¼è§†é¢‘æ·»åŠ è§†é¢‘è½¨é“
                start_time, script = add_video_material(start_time, output_video_path, transform_x=-0.5,
                                                        transform_y=-0.5)

                # æ·»åŠ é™æ­¢å›¾ç‰‡
                add_end_frame_image(script, start_time, output_path_end, transform_x=-0.5, transform_y=-0.5)

            elif idx == 3 and i % 4 == 3:
                if i == 3:
                    # æ·»åŠ é¦–å¸§å›¾ç‰‡
                    # ç”Ÿæˆæ¯ä¸ªè½¨é“çš„è‰ç¨¿è„šæœ¬
                    script.add_track(draft.Track_type.video, track_name=f'{idx}-{output_path_start}-image',
                                     relative_index=idx * 2 - i)
                    video_material = draft.Video_material(output_path_start)
                    video_segment = draft.Video_segment(video_material,
                                                        target_timerange=draft.Timerange(0, start_time),
                                                        source_timerange=draft.Timerange(0, video_material.duration),
                                                        clip_settings=Clip_settings(scale_x=0.5, scale_y=0.5,
                                                                                    transform_x=0.5,
                                                                                    transform_y=-0.5))  # ä¸ç´ æç­‰é•¿
                    # æ·»åŠ åˆ°è½¨é“
                    script.add_segment(video_segment, f'{idx}-{output_path_start}-image', )
                # ç¬¬å››ä¸ªå®«æ ¼è§†é¢‘æ·»åŠ è§†é¢‘è½¨é“
                start_time, script = add_video_material(start_time, output_video_path, transform_x=0.5,
                                                        transform_y=-0.5)
                # æ·»åŠ é™æ­¢å›¾ç‰‡
                add_end_frame_image(script, start_time, output_path_end, transform_x=0.5, transform_y=-0.5)

            else:
                video_material = draft.Video_material(output_video_path)
                start_time += video_material.duration

    script.dump(DUMP_PATH)

    print("\nğŸ‰ æ‰€æœ‰è§†é¢‘ç‰‡æ®µåŠæˆªå›¾å·²æˆåŠŸå¤„ç†ï¼")

    ctrl = draft.Jianying_controller()
    OUTPUT_PATH = os.path.join(root_dir, "output")
    os.makedirs(OUTPUT_PATH, exist_ok=True)
    now_date = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    output_path = os.path.join(OUTPUT_PATH, f"{draft_folder_name}_{now_date}.mp4")
    ctrl.export_draft(draft_folder_name, output_path,
                      resolution=Export_resolution.RES_1080P,
                      framerate=Export_framerate.FR_24,
                      )
    print(f"å¯¼å‡ºè§†é¢‘å®Œæˆ: {output_path}")

    # ä½¿ç”¨è§†é¢‘é•¿åº¦è£å‰ªè§†é¢‘
    output_video = VideoFileClip(output_path)

    # ä½¿ç”¨åŸå§‹è§†é¢‘çš„ duration è¿›è¡Œè£å‰ª
    clipped_video = output_video.subclipped(0, video.duration)

    # ä¿å­˜è£å‰ªåçš„è§†é¢‘
    clipped_output_path = os.path.join(OUTPUT_PATH, f"{draft_folder_name}_{now_date}_è£å‰ªç‰ˆ.mp4")
    clipped_video.write_videofile(clipped_output_path, codec="libx264", audio_codec="aac")

    print(f"âœ… è§†é¢‘å·²è£å‰ªå¹¶ä¿å­˜è‡³: {clipped_output_path}")

    return clipped_output_path
